{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 11476372,
          "sourceType": "datasetVersion",
          "datasetId": 7192663
        }
      ],
      "dockerImageVersionId": 31012,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade google-generativeai\n",
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-19T23:35:31.174534Z",
          "iopub.execute_input": "2025-04-19T23:35:31.174925Z",
          "iopub.status.idle": "2025-04-19T23:35:40.770276Z",
          "shell.execute_reply.started": "2025-04-19T23:35:31.174899Z",
          "shell.execute_reply": "2025-04-19T23:35:40.769081Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xdw60sZdiNkO",
        "outputId": "b05a6ce3-edb4-4f50-9b2b-9b56efe9595f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/155.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m153.6/155.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "try:\n",
        "\n",
        "  from google.colab import userdata\n",
        "  api_key = userdata.get('GEMINI_API_KEY')\n",
        "  genai.configure(api_key=api_key)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"❌ Gemini API setup failed:\", str(e))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-19T23:28:19.281433Z",
          "iopub.execute_input": "2025-04-19T23:28:19.281863Z",
          "iopub.status.idle": "2025-04-19T23:28:22.381211Z",
          "shell.execute_reply.started": "2025-04-19T23:28:19.281821Z",
          "shell.execute_reply": "2025-04-19T23:28:22.380359Z"
        },
        "id": "3Ugtt72TiNkP"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    url = \"https://raw.githubusercontent.com/incribo-inc/cybersecurity_attacks/37f147e47d8772ae7fdd6713b25ea33395e0ddc3/cybersecurity_attacks.csv\"\n",
        "    df = pd.read_csv(url)\n",
        "    print(\"✅ Dataset loaded from GitHub. Shape:\", df.shape)\n",
        "except Exception as e:\n",
        "    print(\"❌ Error loading dataset from GitHub:\", str(e))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-19T23:31:25.388022Z",
          "iopub.execute_input": "2025-04-19T23:31:25.388402Z",
          "iopub.status.idle": "2025-04-19T23:31:26.133930Z",
          "shell.execute_reply.started": "2025-04-19T23:31:25.388365Z",
          "shell.execute_reply": "2025-04-19T23:31:26.132757Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NTM3emYiNkQ",
        "outputId": "417f9a39-6e3c-4f1f-913b-7c9d0c8903a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset loaded from GitHub. Shape: (40000, 25)\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "You are a cybersecurity SOC AI Assistant. Given a detailed network log, analyze the event and return:\n",
        "\n",
        "1. A clear summary of what happened.\n",
        "2. The MITRE ATT&CK technique ID and name (if applicable).\n",
        "3. Recommended response actions for the SOC analyst.\n",
        "\n",
        "Example:\n",
        "\n",
        "Log:\n",
        "Timestamp: 2023-05-30 06:33:58\n",
        "Source IP Address: 103.216.15.12\n",
        "Destination IP Address: 84.9.164.252\n",
        "Protocol: ICMP\n",
        "Packet Type: Data\n",
        "Traffic Type: HTTP\n",
        "Payload Data: Qui natus odio asperiores nam. Optio nobis iusto eos.\n",
        "Severity Level: Low\n",
        "User: Reyansh Dugal\n",
        "Action Taken: Logged\n",
        "\n",
        "Summary: On May 30, 2023, a low-severity ICMP data packet was logged from source 103.216.15.12 targeting 84.9.164.252 over HTTP. The payload did not indicate clear malicious intent, and the event was logged for reference.\n",
        "\n",
        "MITRE: None applicable (no suspicious behavior detected)\n",
        "\n",
        "Actions: Monitor for repeat occurrences, correlate with other logs if similar patterns reappear.\n",
        "\n",
        "---\n",
        "\n",
        "Log:\n",
        "{log}\n",
        "Summary:\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-19T23:31:39.012898Z",
          "iopub.execute_input": "2025-04-19T23:31:39.013384Z",
          "iopub.status.idle": "2025-04-19T23:31:39.020596Z",
          "shell.execute_reply.started": "2025-04-19T23:31:39.013344Z",
          "shell.execute_reply": "2025-04-19T23:31:39.019549Z"
        },
        "id": "y7lk_ZmHiNkQ"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_log(log_text):\n",
        "    try:\n",
        "        prompt = prompt_template.format(log=log_text)\n",
        "        model = genai.GenerativeModel(\"models/gemini-pro\")\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"❌ Error during summarization: {str(e)}\"\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-19T23:31:53.931735Z",
          "iopub.execute_input": "2025-04-19T23:31:53.932049Z",
          "iopub.status.idle": "2025-04-19T23:31:53.938014Z",
          "shell.execute_reply.started": "2025-04-19T23:31:53.932024Z",
          "shell.execute_reply": "2025-04-19T23:31:53.936736Z"
        },
        "id": "wG3InSJ-iNkQ"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X10-CnJEkumy",
        "outputId": "3d23b11f-a5f3-4bd1-9af8-08b8b10f17de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss"
      ],
      "metadata": {
        "id": "Wlf_eZMBk-_0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "cIflxiEmk-8P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Convert DataFrame rows into text blocks\n",
        "    logs_as_text = df.astype(str).apply(lambda row: \"\\n\".join(f\"{col}: {val}\" for col, val in row.items()), axis=1).tolist()\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    X = vectorizer.fit_transform(logs_as_text).toarray().astype(\"float32\")\n",
        "\n",
        "    index = faiss.IndexFlatL2(X.shape[1])\n",
        "    index.add(X)\n",
        "\n",
        "    def search_similar_logs(query, top_k=2):\n",
        "        try:\n",
        "            q_vec = vectorizer.transform([query]).toarray().astype(\"float32\")\n",
        "            _, idxs = index.search(q_vec, top_k)\n",
        "            return [logs_as_text[i] for i in idxs[0]]\n",
        "        except Exception as e:\n",
        "            return [f\"❌ Error during similarity search: {str(e)}\"]\n",
        "\n",
        "    print(\"✅ Vector search engine initialized!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"❌ Vector engine setup failed:\", str(e))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-19T23:35:47.521355Z",
          "iopub.execute_input": "2025-04-19T23:35:47.521707Z",
          "iopub.status.idle": "2025-04-19T23:36:30.490394Z",
          "shell.execute_reply.started": "2025-04-19T23:35:47.521676Z",
          "shell.execute_reply": "2025-04-19T23:36:30.488770Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6r9T2wBiNkR",
        "outputId": "3c877a73-e1ec-495b-a626-a998ad14adc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Vector search engine initialized!\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "def agent_analysis_with_context(log_text):\n",
        "    try:\n",
        "        context_logs = search_similar_logs(log_text)\n",
        "        context = \"\\n\\n---\\n\\n\".join(context_logs)\n",
        "\n",
        "        agent_prompt = f\"\"\"\n",
        "You are an advanced SOC AI Agent. Analyze the following log with the help of historical context.\n",
        "\n",
        "Log:\n",
        "{log_text}\n",
        "\n",
        "Relevant Past Logs:\n",
        "{context}\n",
        "\n",
        "Explain what happened, suggest MITRE ATT&CK techniques, and recommend response actions.\n",
        "\"\"\"\n",
        "        model = genai.GenerativeModel(\"models/gemini-pro\")\n",
        "        response = model.generate_content(agent_prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"❌ Error during agent analysis: {str(e)}\"\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-19T23:36:39.103821Z",
          "iopub.execute_input": "2025-04-19T23:36:39.104261Z",
          "iopub.status.idle": "2025-04-19T23:36:39.112239Z",
          "shell.execute_reply.started": "2025-04-19T23:36:39.104233Z",
          "shell.execute_reply": "2025-04-19T23:36:39.111436Z"
        },
        "id": "gHrmygl5iNkR"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    first_log = df.iloc[0].to_string()\n",
        "    print(\"🔍 Raw Log:\\n\", first_log)\n",
        "\n",
        "    summary = summarize_log(first_log)\n",
        "    print(\"\\n📝 Summary Output:\\n\", summary)\n",
        "\n",
        "    reasoning = agent_analysis_with_context(first_log)\n",
        "    print(\"\\n🧠 Agent Reasoning with Context:\\n\", reasoning)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"❌ Error during processing:\", str(e))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-19T23:36:43.752889Z",
          "iopub.execute_input": "2025-04-19T23:36:43.753253Z",
          "iopub.status.idle": "2025-04-19T23:36:45.116050Z",
          "shell.execute_reply.started": "2025-04-19T23:36:43.753199Z",
          "shell.execute_reply": "2025-04-19T23:36:45.115027Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "GP31ZEDpiNkR",
        "outputId": "80e21ff0-860c-4068-a8c2-7f7421560a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Raw Log:\n",
            " Timestamp                                               2023-05-30 06:33:58\n",
            "Source IP Address                                             103.216.15.12\n",
            "Destination IP Address                                         84.9.164.252\n",
            "Source Port                                                           31225\n",
            "Destination Port                                                      17616\n",
            "Protocol                                                               ICMP\n",
            "Packet Length                                                           503\n",
            "Packet Type                                                            Data\n",
            "Traffic Type                                                           HTTP\n",
            "Payload Data              Qui natus odio asperiores nam. Optio nobis ius...\n",
            "Malware Indicators                                             IoC Detected\n",
            "Anomaly Scores                                                        28.67\n",
            "Alerts/Warnings                                                         NaN\n",
            "Attack Type                                                         Malware\n",
            "Attack Signature                                            Known Pattern B\n",
            "Action Taken                                                         Logged\n",
            "Severity Level                                                          Low\n",
            "User Information                                              Reyansh Dugal\n",
            "Device Information        Mozilla/5.0 (compatible; MSIE 8.0; Windows NT ...\n",
            "Network Segment                                                   Segment A\n",
            "Geo-location Data                                        Jamshedpur, Sikkim\n",
            "Proxy Information                                              150.9.97.135\n",
            "Firewall Logs                                                      Log Data\n",
            "IDS/IPS Alerts                                                          NaN\n",
            "Log Source                                                           Server\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:404 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2042.29ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📝 Summary Output:\n",
            " ❌ Error during summarization: 404 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
            "\n",
            "🧠 Agent Reasoning with Context:\n",
            " ❌ Error during agent analysis: 404 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:404 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 606.28ms\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "Ziky0aARiNkR"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}